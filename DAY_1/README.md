DAY 1 


## Overview

This README provides an overview of a PySpark data analysis script designed to explore and analyze a dataset. The script uses PySpark to load and perform basic operations on the dataset.

## Prerequisites

Before running the code, ensure you have the following prerequisites:

1. Python installed (Python 3 recommended).
2. Apache Spark installed and configured.
3. `findspark` library installed (`pip install findspark`).

## Usage

1. Initialize a PySpark session.

2. Load the dataset into a Spark DataFrame.

3. Get an overview of the DataFrame, including its schema and sample data.

4. Calculate basic statistics such as count, mean, and quartiles.

5. Obtain the number of observations (rows) in the dataset.

6. Determine the number of columns in the dataset.

7. Print the names of all columns in the dataset.

## Running the Code

Execute the Python script using your preferred Python interpreter. Ensure that Apache Spark is correctly configured on your system.

